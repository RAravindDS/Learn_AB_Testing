{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is AB Testing? \n",
    "\n",
    "Essentially a AB testing is a tool that helps you to make decision based on the **data** or make **reliable decisions** based on the data. This is often called **Mulitvariate** or **Hypothesis** testing and also called as **Experimentation**. \n",
    "\n",
    "This is the tool that allows companies with digital products but actually not only digital products to understand whether the improvement that they're trying to implement in their producat actually an improvment. \n",
    "\n",
    "\n",
    "Let's say you have a product; 10k peopare are using that. Now you want to introduce some new feature to the product instead of launching a new feature to everyone you will do a sample from your population and you can show the new feature to the sample, then based on how those users interact with this feature, whether they like it or not, whether they are more engaged or not; depending on what is the success metric for this experiment, you can see how the rest of the population will react to this feature (this is the expermient approximation, it will give how rest of the users will react to your new feature). You can evaluvate this experiment, if the experiment result is positive you can rollout the new feature to all the users. This approach to decision making is **A/B Testing**. \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/ab_testing.png\" width=\"500px\"></p>\n",
    "\n",
    "## 1. Key Characteristics of the A/B Testing\n",
    "\n",
    "A/B Testing is a **Decision Making support** & **research** methodoly. It allows you to measure an impact of a change in a product. It is a controlled experiment where you can determine how a changing experience affects dependents metrics.  \n",
    "\n",
    "### 1.1 Answers to the Questions\n",
    "   1. Which metrics or user behavior change and how much do they change. \n",
    "   2. Is the change reliabe? \n",
    "\n",
    "### 1.2 Does not answer to the questions\n",
    "  1. Why did the change occur? \n",
    "  2. Do the users like the change? \n",
    "\n",
    "\n",
    "It will be used in multiple domains however it used extensively in **digital products**, **Hypothesis testing** in medicine. \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/key_characteristics.png\" width=\"500px\"></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How A/B Tests are Created?\n",
    "\n",
    "##### 1. Define a hypothesis\n",
    "> Define an assumption on how the change will affect the users. This is typically the responsibility of project managers, who should consider the company's goals and direction when defining the hypothesis.\n",
    "\n",
    "##### 2. Decide how to design the feature\n",
    "> Decide what to add to the feature.\n",
    "\n",
    "##### 3. Build the feature\n",
    "\n",
    "##### 4. Determine how to measure success of the feature\n",
    "\n",
    "##### 5. Determine how to run A/B tests\n",
    "    ###### 5.1 For how long do we run the A/B tests?\n",
    "    ###### 5.2 How many users do we want to assign to the test (sample)?\n",
    "    ###### 5.3 How do we monitor the performance of the test?\n",
    "\n",
    "##### 6. Analyzing the results\n",
    "\n",
    "##### 7. Make the decision ðŸ˜€\n",
    "> Decide whether to **Iterate the test**, **release to all users**, or **stop the test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How the data is collected for testing? \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/data_infrastructure.png\" width=\"500px\"></p>\n",
    "\n",
    "Here data are collected in by the app as a **Raw Tracking events** and then it's get cleaned and tranformed to **low level agggregations** moreover **Business level aggregations**. We will give only focus on the **cleaned events**, **low level aggregations** and **Business level agggregations**. \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/aggregations.png\" width=\"500px\"></p>\n",
    "\n",
    "**Data Reporting** will be done by some visualizations tools by some consultants. \n",
    "\n",
    "**Now see this in our usecase**: \n",
    "<p style=\"text-align:center;\"><img src=\"images/user_activity.png\" width=\"500px\"></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Designing A/B Testing \n",
    "\n",
    "Frist of all you need to check **which idea is worth testing?** before starting the test. There are lot of reasons for not to test. Some of them are mentioned bellow \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/reasons_not_to_test.png\" width=\"500px\"></p>\n",
    "\n",
    "Not let's see how to find the right idea to test; It's done by **Quantitative** and **Qualitative** analysis. \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"images/reasons_to_test.png\" width=\"500px\"></p>\n",
    "\n",
    "\n",
    "More **Importantly**; to define a right idea to test, you also need to define a **right hypothesis**. \n",
    "\n",
    "#### 4.1 What is Hypothesis?\n",
    "\n",
    "Essentialy **hypothesis** is what do you expect to happen if you introduce the new feature? or the change to your product?. It's a **Statement** that you will **support** or **disprove** with the A/B test. There are two types of hypothesis     \n",
    "\n",
    "    i) **Base Hypothesis** (H1): It's usually phrases as what you expect would happen when you introduce the change you are testing. It should be very specific and measurable, indetifying **independent variable** (which you can contorl and change for the test) and **dependent variable** (which indicates the impact of the test and should ideally depend on the independent variable). \n",
    "    \n",
    "    ii) **Null Hypothesis** (H0): It's essentially the reverse of your Base Hypothesis. For the hypothesis testing you cannot prove your base hypothesis instead you need to disprove the Null hypothesis. \n",
    "\n",
    "#### 4.2 What is Success Metric? \n",
    "\n",
    "Success metric is basically a metric of success of the A/B test. It's based on the hypothesis testing - it is the dependent variable. However, it's very common for the companies to have multiple dependent variables depending on how much tracking and data is available or can be built for the test. Examples like \"CTR\", \"affiliate revenue** and more.\n",
    "\n",
    "#### 4.3 What is Guardrail Metric? \n",
    "\n",
    "Apart from having a success metric, it's very common to have a metric called **guardrail metrics**. So you make sure that some critical business metris are not affected in negative way, so apart from the clear dependent varialbe we can have other metrics impacted by the chagne we are introducing. Some of them might be unexpected, some might be unimportant, but some may be very business critical. \n",
    "\n",
    "Usually, we want to control the test impact for the business-critical metrics. We would define the non-inferiority margin for those critical metrics. How much can it decrease/increase depending on the varaible so that we still consider the test a success? \n",
    "\n",
    "It's very common to use that **retention** and **engagement metrics** as the guardrail metrics as well as some more technical metrics like **number of errors** and **crases**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
